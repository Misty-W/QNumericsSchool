<!-- Header -->
@@jumbotron,jumbotron-fluid,no-pad
  @@container
    ~~~
    <img src="./assets/logo-placeholder.png" style="max-width:60%;padding-bottom:20px"/>
    <h2>Numerical Methods <br>in Quantum Information Science</h2>
    Summer School at the Mt Ida campus of UMass Amherst on the outskirts of Boston
    ~~~

    @@buttons
      ~~~
      <a class="btn btn-primary btn-lg" href="https://qnumerics.org/register" role="button"><i class="fas fa-user-plus"></i> Register</a>
      ~~~
    @@
  @@
@@

@@features
  @@container
    @@row
      @@col-md-12,feature-title
        ~~~
        <h2>Features</h2>
        ~~~
        Flux has features that sets it apart among ML systems.
      @@
    @@

    @@row
      @@col-md,feature
        ~~~
        <h5>Compiled Eager Code</h5>
        ~~~
        Flux provides a single, intuitive way to define models, just like mathematical notation. Julia transparently [compiles your code](https://julialang.org/blog/2018/12/ml-language-compiler), optimising and fusing kernels for the GPU, for the best performance.
      @@
      @@col-md,feature
        ~~~
        <h5>Differentiable Programming</h5>
        ~~~
        Existing Julia libraries are differentiable and can be incorporated directly into Flux models. Cutting edge models such as [Neural ODEs](https://julialang.org/blog/2019/01/fluxdiffeq) are first class, and [Zygote](https://github.com/FluxML/Zygote.jl) enables overhead-free gradients.
      @@
      @@col-md,feature
        ~~~
        <h5>First-class GPU support</h5>
        ~~~
        GPU kernels can be written directly in Julia via [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl). Flux is uniquely hackable and any part can be tweaked, from GPU code to custom gradients and layers.
      @@
    @@
  @@
@@

@@features
  @@container
    @@row
      @@col-md-12,feature-title
        ~~~
        <h2>
          Ecosystem
        </h2>
        ~~~
        Flux has a diverse ecosystem that includes models available for reuse and other useful packages.
      @@
      @@col-md-12,feature-title
      ~~~
      <a class="btn btn-primary btn-lg" href="https://fluxml.ai/Flux.jl/dev/ecosystem/" role="button" style="float: right;">See all <i class="fas fa-arrow-circle-right"></i> </a>
      ~~~
      @@
    @@

    @@row
      @@col-md,feature
        ~~~
        <h5>Probabilistic Programming</h5>
        ~~~
        The [Turing.jl](https://github.com/TuringLang/Turing.jl) and [Stheno.jl](https://github.com/willtebbutt/Stheno.jl) libraries enable probabilistic programming, Bayesian inference and Gaussian processes on top of Flux.
      @@
      @@col-md,feature
        ~~~
        <h5>Graph Neural Networks</h5>
        ~~~
        [GraphNeuralNetworks.jl](https://github.com/CarloLucibello/GraphNeuralNetworks.jl) is a graph neural network library for Flux and supports CUDA GPU acceleration.
      @@
      @@col-md,feature
        ~~~
        <h5>Computer Vision</h5>
        ~~~
        [Metalhead.jl](https://github.com/FluxML/Metalhead.jl) includes many state-of-the-art computer vision models with pre-trained weights.
      @@
    @@

    @@row
      @@col-md,feature
        ~~~
        <h5>SciML</h5>
        ~~~
        The [SciML](https://sciml.ai/) ecosystem uses the FluxML stack to mix neural nets with differential equations, to get the best of black box and mechanistic modelling.
      @@
      @@col-md,feature
        ~~~
        <h5>Natural Language Processing</h5>
        ~~~
        [Transformers.jl](https://github.com/chengchingwen/Transformers.jl) provides components for transformer architectures for language modeling, as well as providing several trained models out of the box.
      @@
    @@
  @@
@@

@@friends
  @@container
    @@row
      @@col-md-12,feature-title
        ~~~
        <h2>Sponsors, Presenters, and Instructors</h2>
        ~~~
      @@
    @@

    @@row
      @@col-md
        ~~~
        <img src="./assets/logo-umass.png">
        ~~~
      @@
      @@col-md
        ~~~
        <img src="./assets/friends/cqn-logo.png" style="background-color:black;">
        ~~~
      @@
      @@col-md
        ~~~
        <img src="./assets/friends/mit-logo.png">
        ~~~
      @@
      @@col-md
        ~~~
        <img src="./assets/friends/juliac-logo.png">
        ~~~
      @@
      @@col-md
        ~~~
        <img src="./assets/friends/quera-logo.svg" style="background-color:black;">
        ~~~
      @@
      @@col-md
        ~~~
        <img src="./assets/friends/nsf-logo.png">
        ~~~
      @@

    @@

  @@
@@
